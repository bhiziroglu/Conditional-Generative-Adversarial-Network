{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Generative Adversarial Network Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial will explain how to implement and train [Conditional GAN](https://arxiv.org/pdf/1411.1784.pdf) using PyTorch. I assume that the reader is already familiar with implementing the original GAN. I will build on PyTorch's official GAN implementation to create a Conditional GAN. CIFAR-10 dataset is used.\n",
    "\n",
    "In short, Conditional GAN is just like the original GAN but it does not generate the output randomly. It conditions itself on a variable to generate an output. It means that we can manually make the model generate images from a certain class. For example, if a Conditional GAN is trained on CIFAR-10 images, we can make it generate only dog images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/disc_arch.png\" alt=\"drawing\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/gen_arch.png\" alt=\"drawing\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The architectures given above are from PyTorch's official GAN implementation for CIFAR-10 dataset. Our task is to convert it to a Conditional GAN (CGAN).\n",
    "\n",
    "If you look at Equation 2 at [1], you can see that the value function differs from the original GAN's value function slightly. The authors introduced the <strong>y</strong> term in the CGAN. <strong>y</strong> is the extra information that we are conditioning our model on.\n",
    "\n",
    "The following text is from the paper and it summarizes the importance of the <strong>y</strong> term.\n",
    "\n",
    "\"Generative adversarial nets can be extended to a conditional model if both the generator and discriminator are conditioned on some extra information y. y could be any kind of auxiliary information,\n",
    "such as class labels or data from other modalities.\" [1]\n",
    "\n",
    "So, we can transform the GAN implementation to a CGAN by introducing a <strong>y</strong> term both to the discriminator and the generator.\n",
    "\n",
    "The rest of this tutorial differs from the CGAN paper because the paper generates MNIST images, not CIFAR-10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN Architecture Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the original GAN code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        def forward(self, x):\n",
    "            return self.main(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(     nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d(ngf * 2,     ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d(    ngf,      nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 64 x 64\n",
    "        )\n",
    "        \n",
    "        def forward(self, x):\n",
    "            return self.main(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the Conditional Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The authors state that \"the adversarial training framework allows for considerable flexibility in how this hidden representation is composed.\" [1]\n",
    "\n",
    "My understanding from this is, the <strong>y</strong> term can be anything as long as the same <strong>y</strong> is used both for the generator and the discriminator.\n",
    "\n",
    "Since we are using the CIFAR-10 dataset, we have 10 classes. Let's create an Embedding Matrix that maps the 10 classes to 100 dimensional vectors. Here, the <strong>y</strong> term is the 100-dimensional vector for each class.\n",
    "\n",
    "This can be done easily using PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = nn.Embedding(10,100)\n",
    "embeddings.weight.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embedding matrix we have created should not be trained at all. The values that are generated when creating the matrix are not important. (I mean not important numerically.) They could be anything. The important thing is that the conditional variable is same throughout the training and also in the evaluation. So make sure that the weights of the embedding matrix are non-trainable by setting requires_grad to be False. \n",
    "\n",
    "Now that we have the <strong>y</strong> vector, how should we add it to the model?\n",
    "\n",
    "To keep thing simple, I decided not to change the original GAN architecture's forward pass. So, for both the discriminator and the generator, I merged the input (input is noise for the generator and an image for the discriminator) with the conditional variable <strong>y</strong> and used the result as an input to the original GAN architecture. This still works because I make sure that the input dimensions are still same for the both models after merging. The merging steps for the discriminator and the generator are:\n",
    "\n",
    "    __Generator__\n",
    "    \n",
    "    label_embed = embedding_layer(label) # [batchsize x 100]\n",
    "    \n",
    "    noise = torch.cat([noise, label_embed], dim=1) # [batchsize x 200]\n",
    "\n",
    "    noise = linear_layer(noise) # [batchsize x 100]\n",
    "    \n",
    "    __Discriminator__\n",
    "    \n",
    "    label_embed = embedding_layer(label) # [batchsize x 100]\n",
    "\n",
    "    label_map = linear_layer(label_embed) # [batchsize x 3072]\n",
    "\n",
    "    label_map = label_map.view(-1,3,32,32) # [batchsize x 3 x 32 x 32]\n",
    "\n",
    "    im = torch.cat([im,label_map], dim=1) # [batchsize x 6 x 32 x 32]\n",
    "\n",
    "    out = conv_layer(x) # [batchsize x 3 x 32 x 32]\n",
    "    \n",
    "label_embed is the 100-dimensional vector (<strong>y</strong>). To make the input for both model same dimension respectively, I applied the above steps. So, the generator still takes a matrix of size [batchsize x 100] and the discriminator a matrix of size [batchsize x 3 x 32 x 32]\n",
    "\n",
    "The discriminator and the generator codes look like this after making these changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, embeddings, nc=3, ndf=64):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.embeddings = embeddings\n",
    "        self.label_to_image = nn.Linear(100,32*32*3)\n",
    "        self.conv1 = nn.Conv2d(nc * 2, nc, 1, 1, 0, bias=False)\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        def forward(self, x, label_embed):\n",
    "            \n",
    "            label_embed = self.embeddings(label_embed)\n",
    "\n",
    "            label_map = self.label_to_image(label_embed)\n",
    "            label_map = label_map.view(-1,3,32,32)\n",
    "\n",
    "            x = torch.cat([x,label_map], dim=1)\n",
    "\n",
    "            out = self.conv1(x)\n",
    "            output = self.main(out)\n",
    "\n",
    "            return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, embeddings, nc=3, nz=100, ngf=64):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.embeddings = embeddings\n",
    "        self.linear = nn.Linear(200,100)\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(     nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d(ngf * 2,     ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d(    ngf,      nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 64 x 64\n",
    "        )\n",
    "        \n",
    "        def forward(self, x, label_embed):\n",
    "            label_embed = self.embeddings(label_embed)\n",
    "\n",
    "            x = x.view(-1,100)\n",
    "            x = torch.cat([x,label_embed], dim=1)\n",
    "\n",
    "            x = self.linear(x)\n",
    "            x = x.unsqueeze(2).unsqueeze(3)\n",
    "\n",
    "            output = self.main(x)\n",
    "            return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And it's done. We have implemented the CGAN. Now, we can train and look at the outputs.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training is same with the original GAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batchsize = 200\n",
    "epochs = 500\n",
    "\n",
    "train_data = Data(file_name=\"cifar-10-batches-py/\")\n",
    "train_data_loader = torch.utils.data.DataLoader(train_data, batch_size=batchsize,shuffle=True,drop_last=True)\n",
    "\n",
    "\n",
    "embeddings = nn.Embedding(10,100)\n",
    "embeddings.weight.requires_grad = False\n",
    "\n",
    "netD = Discriminator(embeddings)\n",
    "netG = Generator(embeddings)\n",
    "\n",
    "\n",
    "optimizerD = optim.Adam(netD.parameters(),lr=0.0002,betas=(0.5, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(),lr=0.0002,betas=(0.5, 0.999))\n",
    "\n",
    "netD.train()\n",
    "netG.train()\n",
    "\n",
    "nz = 100\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "real_label = torch.ones([batchsize,1], dtype=torch.float).to(device)\n",
    "fake_label = torch.zeros([batchsize,1], dtype=torch.float).to(device)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, (input_sequence, label) in enumerate(train_data_loader):\n",
    "        \n",
    "        fixed_noise = torch.randn(batchsize, nz, 1, 1, device=device)\n",
    "\n",
    "        input_sequence = input_sequence.to(device)\n",
    "        label_embed = label.to(device)\n",
    "        \n",
    "        '''\n",
    "            Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        '''\n",
    "\n",
    "        D_real_result = netD(input_sequence, label_embed)\n",
    "        D_real_loss = criterion(D_real_result.view(batchsize,-1), real_label)\n",
    "\n",
    "        G_result = netG(fixed_noise,label_embed)\n",
    "\n",
    "        D_fake_result = netD(G_result,label_embed)\n",
    "\n",
    "        D_fake_loss = criterion(D_fake_result.view(batchsize,-1), fake_label)\n",
    "\n",
    "        # Back propagation\n",
    "        D_train_loss = (D_real_loss + D_fake_loss) / 2\n",
    "\n",
    "        netD.zero_grad()\n",
    "        D_train_loss.backward()\n",
    "        optimizerD.step()\n",
    "\n",
    "        '''\n",
    "            Update G network: maximize log(D(G(z)))\n",
    "        '''\n",
    "        new_label = torch.LongTensor(batchsize,10).random_(0, 10).to(device)\n",
    "        new_embed = new_label[:,0].view(-1)\n",
    "\n",
    "        G_result = netG(fixed_noise, new_embed)\n",
    "\n",
    "        D_fake_result = netD(G_result, new_embed)\n",
    "        G_train_loss = criterion(D_fake_result.view(batchsize,-1), real_label)\n",
    "\n",
    "\n",
    "        # Back propagation\n",
    "        netD.zero_grad()\n",
    "        netG.zero_grad()\n",
    "        G_train_loss.backward()\n",
    "        optimizerG.step()\n",
    "        \n",
    "        print(\"D_loss:%f\\tG_loss:%f\" % (D_train_loss,G_train_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I trained the model with two different hyperparameter settings and below are the generated images. I conditioned each row on a specific class. Some images do not look very nice and there seems to be mode collapse but I think that if I had more resources and could train the model longer, the results would be better. Nevertheless, I think it is clear that the way this model uses the conditional variable works. Each row has images from a specific class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/results1.png\" alt=\"drawing\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/results2.png\" alt=\"drawing\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] Conditional Generative Adversarial Nets [arXiv](https://arxiv.org/pdf/1411.1784.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
